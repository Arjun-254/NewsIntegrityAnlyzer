from fastapi import Depends, FastAPI, HTTPException, status, Header, Body
from fastapi.middleware.cors import CORSMiddleware
import requests
from bs4 import BeautifulSoup

#ML Imports
from transformers import pipeline
import google.generativeai as genai
from transformers import AutoTokenizer, AutoModelForSequenceClassification
import torch

#Imports from my files
from scrapingbsf import make_data
from scraping_selenium import people_also_ask
from schemas import inputRequest

app = FastAPI(title="IPD Back-End",)
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

genai.configure(api_key="AIzaSyAYwK3xLs3CoOevA29JgDUuMCx_rGQQIgA")
gemini_model = genai.GenerativeModel('gemini-pro')

@app.get("/")
def read_root():
    return {"You're not": "supposed to be here"}
#-------------------------------------------------------------------------------------------------------------------------------------
@app.post("/FactCC-QnA")
async def quick_search(request: inputRequest):
    quickSearchAnswer = google_search(request.input)

    #compare scraped info as source and headline as the claim
    ans = pipe([[[quickSearchAnswer,request.input]]], truncation=True, padding='max_length')

    # Display the result
    if ans[0]['label'] == 'INCORRECT':
        ans[0]['score'] = 1 - ans[0]['score']
    
    classification_result = {
        "label": ans[0]['label'],
        "score": ans[0]['score']
    }
    return {'scrapedContent':quickSearchAnswer,'result':classification_result}
#-------------------------------------------------------------------------------------------------------------------------------------
#To answer the question generated by gemini via google
def google_search(query):
    headers = {
        'User-agent':
        'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/101.0.4951.67 Safari/537.36'
    }
    
    # Perform the Google search
    search_url = f'https://www.google.com/search?q={query}'
    html = requests.get(search_url, headers=headers)
    
    # Parse the HTML response
    soup = BeautifulSoup(html.text, 'html.parser')
    
    # Extract the answer (assuming it's in a specific class)
    if soup.select_one('.DI6Ufb'):
        answer = soup.select_one('.DI6Ufb')
        answer = answer.find(class_='Z0LcW t2b5Cf').text
        answer=query+' '+answer
    
    elif not soup.select_one('.DI6Ufb'):
        result=people_also_ask(search_url)
        if len(result)==2:
            answer=f'{result[0]} {result[1]}'
        else:
            answer = 'Could not retrieve articles related to headline, Could possibly be a false claim.'
    
    return answer

@app.post("/FactCC-gemini")
async def gemini(request: inputRequest):
    
    response = gemini_model.generate_content(
        f'''You're tasked with fact-checking news headlines for accuracy. Given a headline, generate 1 questions that needs to be true to verify the headlines authenticity using a Google search to scrape the answer from the quick search box. 
            Ask the crucial questions first. Your output should only be in the form of a string for me to ingest in my backend without any other text.
            The headline is : {request.input}'''
    )

    quickSearchAnswer = google_search(response.text)
    
    #compare scraped info as source and headline as the claim
    ans = pipe([[[quickSearchAnswer,request.input]]], truncation=True, padding='max_length')

    # Display the result
    if ans[0]['label'] == 'INCORRECT':
        ans[0]['score'] = 1 - ans[0]['score']
    
    classification_result = {
        "label": ans[0]['label'],
        "score": ans[0]['score']
    }
    return {"generatedGeminiQuestion": response.text,'scrapedContent':quickSearchAnswer,'result':classification_result}

#-------------------------------------------------------------------------------------------------------------------------------------

#To scrape headlines for the FactCC endpoint
def dataframegen(text_input):
    scraped_df = make_data(text_input)
    scraped_df.dropna(inplace=True)
    return scraped_df

pipe = pipeline(model="manueldeprada/FactCC", task="text-classification", max_length=512)

@app.post("/FactCC-articles")
async def factCC(request: inputRequest):
    scraped_df =  dataframegen(request.input)

    #To make sure best scraped article picked
    scraped_df = scraped_df.sort_values(by='Content', key=lambda x: x.str.len(), ascending=False) 

    if len(scraped_df) == 0 or not scraped_df['Title'][0] or '403 Forbidden' in scraped_df['Content'][0] or '403 Forbidden' in scraped_df['Title'][0] :
        raise HTTPException(status_code=404, detail="Could not retrieve articles related to headline, Could possibly be a false claim.")

    scraped_content = (
    f"{scraped_df['Title'][0]} \n{scraped_df['Content'][0]}")
    
    # Perform text classification [source,claim]
    ans = pipe([[[scraped_content,request.input]]], truncation=True, padding='max_length')

    # Display the result
    if ans[0]['label'] == 'INCORRECT':
        ans[0]['score'] = 1 - ans[0]['score']
    
    classification_result = {
        "label": ans[0]['label'],
        "score": ans[0]['score']
    }
    return {'article':scraped_content,'result':classification_result}

#-------------------------------------------------------------------------------------------------------------------------------------
def perform_text_classification(scraped_content, claim):
    # Perform text classification [source, claim]
    ans = pipe([[[scraped_content, claim]]], truncation=True, padding='max_length')

    # Display the result
    if ans[0]['label'] == 'INCORRECT':
        ans[0]['score'] = 1 - ans[0]['score']

    classification_result = {
        "label": ans[0]['label'],
        "score": ans[0]['score']
    }
    return classification_result

def aggregate_results(Gemini_result, QNA_result, Article_result):
    # Aggregate results and return majority-voted label
    gemini_label = Gemini_result["label"]
    qna_label = QNA_result["label"]
    article_label = Article_result["label"]

    # Count votes
    votes = {"CORRECT": 0, "INCORRECT": 0}
    for label in [gemini_label, qna_label, article_label]:
        if label == "CORRECT":
            votes["CORRECT"] += 1
        elif label == "INCORRECT":
            votes["INCORRECT"] += 1

    # Determine final result based on majority voting
    if votes["CORRECT"] >= votes["INCORRECT"]:
        final_label = "CORRECT"
    elif votes["CORRECT"] < votes["INCORRECT"]:
        final_label = "INCORRECT"

    return {'label':final_label,"votes":votes}
@app.post("/FactCC-combined")
async def combined_factCC(request: inputRequest):
    gemini_question = gemini_model.generate_content(
        f'''You're tasked with fact-checking news headlines for accuracy. Given a headline, generate 1 questions that needs to be true to verify the headlines authenticity using a Google search to scrape the answer from the quick search box. 
            Ask the crucial questions first. Your output should only be in the form of a string for me to ingest in my backend without any other text.
            The headline is : {request.input}'''
    )

    scraped_df =  dataframegen(request.input)
    #To make sure best scraped article picked
    scraped_df = scraped_df.sort_values(by='Content', key=lambda x: x.str.len(), ascending=False) 

    if (len(scraped_df) == 0) or (not scraped_df['Title'][0]) or ('403 Forbidden' in scraped_df['Content'][0]) or ('403 Forbidden' in scraped_df['Title'][0]) or (len(scraped_df['Content'][0])<400) :
        scraped_article="Could not retrieve articles related to headline, Could possibly be a false claim."
        Article_result = {
      "label": "NA",
      "score": 0
    }
    else:
        scraped_article = (f"{scraped_df['Title'][0]} \n{scraped_df['Content'][0]}")
        Article_result = perform_text_classification(scraped_article, request.input)
    
    GeminiSearchAnswer = google_search(gemini_question.text)
    QNASearchAnswer = google_search(request.input)
    scraped_article = (f"{scraped_df['Title'][0]} \n{scraped_df['Content'][0]}")

    Gemini_result = perform_text_classification(GeminiSearchAnswer, request.input)
    QNA_result = perform_text_classification(QNASearchAnswer, request.input)
    

    final_result = aggregate_results(Gemini_result, QNA_result, Article_result)

    return {
        "FactCC-gemini": {
            "generatedGeminiQuestion": gemini_question.text,
            "scrapedContent": GeminiSearchAnswer,
            "result": Gemini_result
        },
        "FactCC-qna": {
            "scrapedContent":QNASearchAnswer ,
            "result": QNA_result
        },
        "FactCC-articles": {
            "scrapedContent":scraped_article,
            "result": Article_result
        },
        "FinalResult":final_result
    }



    


#-------------------------------------------------------------------------------------------------------------------------------------
tokenizer_Bert_Binary_FakeReal = AutoTokenizer.from_pretrained(
    "Arjun24420/BERT-FakeOrReal-BinaryClassification")
model_Bert_Binary_FakeReal = AutoModelForSequenceClassification.from_pretrained(
    "Arjun24420/BERT-FakeOrReal-BinaryClassification")

# Define class labels mapping
class_mapping_Bert_Binary_FakeReal = {
    1: 'Reliable',
    0: 'Unreliable',
}

@app.post("/BertBinaryfr")
def predict_Bert_Binary_FakeOrReal(request: inputRequest):
    # Tokenize the input text
    inputs = tokenizer_Bert_Binary_FakeReal(request.input, padding=True, truncation=True,
                       max_length=512, return_tensors="pt")

    # Get model output (logits)
    outputs = model_Bert_Binary_FakeReal(**inputs)

    # Calculate probabilities
    probs = outputs.logits.softmax(1)

    # Get the probabilities for each class
    class_probabilities = {class_mapping_Bert_Binary_FakeReal[i]: probs[0, i].item()
                           for i in range(probs.shape[1])}

    return class_probabilities
#-------------------------------------------------------------------------------------------------------------------------------------